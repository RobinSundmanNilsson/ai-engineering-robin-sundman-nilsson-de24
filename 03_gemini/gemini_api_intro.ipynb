{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d02afd05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are 5 funny jokes about data engineering:\n",
      "\n",
      "1.  What do you call a data engineer who only works with perfectly clean, well-structured data?\n",
      "    A **unicorn**.\n",
      "\n",
      "2.  Why did the data engineer break up with their streaming pipeline?\n",
      "    It was too clingy and kept waking them up at 3 AM.\n",
      "\n",
      "3.  A business analyst walks up to a data engineer and says, \"Can we just add one more column?\"\n",
      "    The data engineer sighs and replies, \"Sure, right after I finish rebuilding the entire data warehouse based on your *last* 'just one more column' request.\"\n",
      "\n",
      "4.  What do you call a data lake with no governance?\n",
      "    A **data swamp**. And what do you call the poor data engineer trying to navigate it? A very tired swamp monster.\n",
      "\n",
      "5.  What's a data engineer's favorite part of a new project?\n",
      "    The part where they get to explain for the 100th time why \"real-time\" doesn't mean \"instant magic from a spreadsheet someone manually updated last week.\"\n"
     ]
    }
   ],
   "source": [
    "from google import genai\n",
    "\n",
    "# the client looks automatically for the environment variable \"GOOGLE_API_KEY\" or \"GEMINI_API_KEY\".\n",
    "client = genai.Client()\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    contents=\"Generate some funny jokes about data engineering. Give 5 points\",\n",
    ")\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6939f465",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are 5 dad jokes for you, structured in short points:\n",
      "\n",
      "1.  *   Why don't scientists trust atoms?\n",
      "    *   Because they make up everything!\n",
      "\n",
      "2.  *   What do you call a fake noodle?\n",
      "    *   An impasta!\n",
      "\n",
      "3.  *   I'm reading a book about anti-gravity.\n",
      "    *   It's impossible to put down!\n",
      "\n",
      "4.  *   Did you hear about the restaurant on the moon?\n",
      "    *   Great food, no atmosphere!\n",
      "\n",
      "5.  *   What's orange and sounds like a parrot?\n",
      "    *   A carrot!\n"
     ]
    }
   ],
   "source": [
    "def ask_gemini(prompt, model=\"gemini-2.5-flash\"):\n",
    "\n",
    "    response = client.models.generate_content(\n",
    "    model=model,\n",
    "    contents=prompt,\n",
    ")\n",
    "    return response\n",
    "\n",
    "response = ask_gemini(\"Give me 5 dad jokes, structure in short points!\")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9bb9c228",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GenerateContentResponse(\n",
       "  automatic_function_calling_history=[],\n",
       "  candidates=[\n",
       "    Candidate(\n",
       "      content=Content(\n",
       "        parts=[\n",
       "          Part(\n",
       "            text=\"\"\"Here are 5 dad jokes for you, structured in short points:\n",
       "\n",
       "1.  *   Why don't scientists trust atoms?\n",
       "    *   Because they make up everything!\n",
       "\n",
       "2.  *   What do you call a fake noodle?\n",
       "    *   An impasta!\n",
       "\n",
       "3.  *   I'm reading a book about anti-gravity.\n",
       "    *   It's impossible to put down!\n",
       "\n",
       "4.  *   Did you hear about the restaurant on the moon?\n",
       "    *   Great food, no atmosphere!\n",
       "\n",
       "5.  *   What's orange and sounds like a parrot?\n",
       "    *   A carrot!\"\"\"\n",
       "          ),\n",
       "        ],\n",
       "        role='model'\n",
       "      ),\n",
       "      finish_reason=<FinishReason.STOP: 'STOP'>,\n",
       "      index=0\n",
       "    ),\n",
       "  ],\n",
       "  model_version='gemini-2.5-flash',\n",
       "  response_id='5_gdaarnC_uDvdIPn_iEyAk',\n",
       "  sdk_http_response=HttpResponse(\n",
       "    headers=<dict len=11>\n",
       "  ),\n",
       "  usage_metadata=GenerateContentResponseUsageMetadata(\n",
       "    candidates_token_count=138,\n",
       "    prompt_token_count=13,\n",
       "    prompt_tokens_details=[\n",
       "      ModalityTokenCount(\n",
       "        modality=<MediaModality.TEXT: 'TEXT'>,\n",
       "        token_count=13\n",
       "      ),\n",
       "    ],\n",
       "    thoughts_token_count=362,\n",
       "    total_token_count=513\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "12dacea9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pydantic import BaseModel\n",
    "\n",
    "# knows that \"GenerateContentResponse\" is a pydantic model\n",
    "# ---> we can work with it in a OOP manner\n",
    "isinstance(response, BaseModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a32cb275",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sdk_http_response': HttpResponse(\n",
       "   headers=<dict len=11>\n",
       " ),\n",
       " 'candidates': [Candidate(\n",
       "    content=Content(\n",
       "      parts=[\n",
       "        Part(\n",
       "          text=\"\"\"Here are 5 dad jokes for you, structured in short points:\n",
       "  \n",
       "  1.  *   Why don't scientists trust atoms?\n",
       "      *   Because they make up everything!\n",
       "  \n",
       "  2.  *   What do you call a fake noodle?\n",
       "      *   An impasta!\n",
       "  \n",
       "  3.  *   I'm reading a book about anti-gravity.\n",
       "      *   It's impossible to put down!\n",
       "  \n",
       "  4.  *   Did you hear about the restaurant on the moon?\n",
       "      *   Great food, no atmosphere!\n",
       "  \n",
       "  5.  *   What's orange and sounds like a parrot?\n",
       "      *   A carrot!\"\"\"\n",
       "        ),\n",
       "      ],\n",
       "      role='model'\n",
       "    ),\n",
       "    finish_reason=<FinishReason.STOP: 'STOP'>,\n",
       "    index=0\n",
       "  )],\n",
       " 'create_time': None,\n",
       " 'model_version': 'gemini-2.5-flash',\n",
       " 'prompt_feedback': None,\n",
       " 'response_id': '5_gdaarnC_uDvdIPn_iEyAk',\n",
       " 'usage_metadata': GenerateContentResponseUsageMetadata(\n",
       "   candidates_token_count=138,\n",
       "   prompt_token_count=13,\n",
       "   prompt_tokens_details=[\n",
       "     ModalityTokenCount(\n",
       "       modality=<MediaModality.TEXT: 'TEXT'>,\n",
       "       token_count=13\n",
       "     ),\n",
       "   ],\n",
       "   thoughts_token_count=362,\n",
       "   total_token_count=513\n",
       " ),\n",
       " 'automatic_function_calling_history': [],\n",
       " 'parsed': None}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2dc01b12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sdk_http_response': HttpResponse(\n",
       "   headers=<dict len=11>\n",
       " ),\n",
       " 'candidates': [Candidate(\n",
       "    content=Content(\n",
       "      parts=[\n",
       "        Part(\n",
       "          text=\"\"\"Here are 5 dad jokes for you, structured in short points:\n",
       "  \n",
       "  1.  *   Why don't scientists trust atoms?\n",
       "      *   Because they make up everything!\n",
       "  \n",
       "  2.  *   What do you call a fake noodle?\n",
       "      *   An impasta!\n",
       "  \n",
       "  3.  *   I'm reading a book about anti-gravity.\n",
       "      *   It's impossible to put down!\n",
       "  \n",
       "  4.  *   Did you hear about the restaurant on the moon?\n",
       "      *   Great food, no atmosphere!\n",
       "  \n",
       "  5.  *   What's orange and sounds like a parrot?\n",
       "      *   A carrot!\"\"\"\n",
       "        ),\n",
       "      ],\n",
       "      role='model'\n",
       "    ),\n",
       "    finish_reason=<FinishReason.STOP: 'STOP'>,\n",
       "    index=0\n",
       "  )],\n",
       " 'create_time': None,\n",
       " 'model_version': 'gemini-2.5-flash',\n",
       " 'prompt_feedback': None,\n",
       " 'response_id': '5_gdaarnC_uDvdIPn_iEyAk',\n",
       " 'usage_metadata': GenerateContentResponseUsageMetadata(\n",
       "   candidates_token_count=138,\n",
       "   prompt_token_count=13,\n",
       "   prompt_tokens_details=[\n",
       "     ModalityTokenCount(\n",
       "       modality=<MediaModality.TEXT: 'TEXT'>,\n",
       "       token_count=13\n",
       "     ),\n",
       "   ],\n",
       "   thoughts_token_count=362,\n",
       "   total_token_count=513\n",
       " ),\n",
       " 'automatic_function_calling_history': [],\n",
       " 'parsed': None}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b430c080",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['sdk_http_response', 'candidates', 'create_time', 'model_version', 'prompt_feedback', 'response_id', 'usage_metadata', 'automatic_function_calling_history', 'parsed'])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(response).keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0edb9600",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gemini-2.5-flash'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.model_version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "45db260b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HttpResponse(\n",
       "  headers=<dict len=11>\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.sdk_http_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "59c070e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Candidate(\n",
       "   content=Content(\n",
       "     parts=[\n",
       "       Part(\n",
       "         text=\"\"\"Here are 5 dad jokes for you, structured in short points:\n",
       " \n",
       " 1.  *   Why don't scientists trust atoms?\n",
       "     *   Because they make up everything!\n",
       " \n",
       " 2.  *   What do you call a fake noodle?\n",
       "     *   An impasta!\n",
       " \n",
       " 3.  *   I'm reading a book about anti-gravity.\n",
       "     *   It's impossible to put down!\n",
       " \n",
       " 4.  *   Did you hear about the restaurant on the moon?\n",
       "     *   Great food, no atmosphere!\n",
       " \n",
       " 5.  *   What's orange and sounds like a parrot?\n",
       "     *   A carrot!\"\"\"\n",
       "       ),\n",
       "     ],\n",
       "     role='model'\n",
       "   ),\n",
       "   finish_reason=<FinishReason.STOP: 'STOP'>,\n",
       "   index=0\n",
       " )]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ae6b1495",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Here are 5 dad jokes for you, structured in short points:\\n\\n1.  *   Why don't scientists trust atoms?\\n    *   Because they make up everything!\\n\\n2.  *   What do you call a fake noodle?\\n    *   An impasta!\\n\\n3.  *   I'm reading a book about anti-gravity.\\n    *   It's impossible to put down!\\n\\n4.  *   Did you hear about the restaurant on the moon?\\n    *   Great food, no atmosphere!\\n\\n5.  *   What's orange and sounds like a parrot?\\n    *   A carrot!\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26d04bd7",
   "metadata": {},
   "source": [
    "## Tokens\n",
    "\n",
    "### thinking is expensive\n",
    "\n",
    "- basic unit of text for LLMs\n",
    "\n",
    "- can be as short as one character or as long as one word\n",
    "\n",
    "- tokens used for billing\n",
    "\n",
    "Gemini free tier\n",
    "\n",
    "- Requests per minute (RPM): 10\n",
    "- Tokens per minute (TPM): 250 000\n",
    "- Requests per day (RPD): 250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "57fe1655",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GenerateContentResponseUsageMetadata(\n",
       "  candidates_token_count=138,\n",
       "  prompt_token_count=13,\n",
       "  prompt_tokens_details=[\n",
       "    ModalityTokenCount(\n",
       "      modality=<MediaModality.TEXT: 'TEXT'>,\n",
       "      token_count=13\n",
       "    ),\n",
       "  ],\n",
       "  thoughts_token_count=362,\n",
       "  total_token_count=513\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.usage_metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56ccaf76",
   "metadata": {},
   "source": [
    "## Thinking\n",
    "\n",
    "- hyperparameter to allocate more compute for complex tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d44e76a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are 5 graffiti jokes, structured in short points:\n",
      "\n",
      "1.  **Q:** Why did the graffiti artist get a promotion?\n",
      "    **A:** Because he really made his mark!\n",
      "\n",
      "2.  **Q:** What's a ghost's favorite kind of graffiti?\n",
      "    **A:** Spook-ghetti!\n",
      "\n",
      "3.  **Q:** Why was the graffiti artist so good at school?\n",
      "    **A:** He was always highlighting things.\n",
      "\n",
      "4.  **Q:** What do you call a graffiti artist who's also a chef?\n",
      "    **A:** A street eater! (Street art + street food)\n",
      "\n",
      "5.  **Q:** My friend said his new graffiti tag looked like a chicken.\n",
      "    **A:** I told him, \"That's *fowl* play!\"\n"
     ]
    }
   ],
   "source": [
    "from google.genai import types\n",
    "\n",
    "prompt = \"Give me 5 graffiti jokes, structure it in short points\"\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    contents=prompt,\n",
    "    config=types.GenerateContentConfig(\n",
    "        thinking_config=types.ThinkingConfig(thinking_budget=0)\n",
    "    ),\n",
    ")\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a3ec491a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GenerateContentResponseUsageMetadata(\n",
       "  candidates_token_count=172,\n",
       "  prompt_token_count=13,\n",
       "  prompt_tokens_details=[\n",
       "    ModalityTokenCount(\n",
       "      modality=<MediaModality.TEXT: 'TEXT'>,\n",
       "      token_count=13\n",
       "    ),\n",
       "  ],\n",
       "  total_token_count=185\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.usage_metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3350ab91",
   "metadata": {},
   "source": [
    "## System instruction\n",
    "\n",
    "- hyperparameter to guide model behavior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d0ecc591",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Okay, here's a concise explanation of OOP and dunder methods in Python:\n",
      "\n",
      "**OOP (Object-Oriented Programming):**\n",
      "\n",
      "*   **Core Idea:** Organize code around \"objects\" that combine data (attributes) and actions (methods).\n",
      "*   **Key Principles:**\n",
      "    *   **Encapsulation:** Bundling data and methods that operate on that data within a class.\n",
      "    *   **Inheritance:** Creating new classes (child/subclasses) based on existing classes (parent/superclasses), inheriting their attributes and methods.\n",
      "    *   **Polymorphism:**  The ability of different classes to respond to the same method call in their own way (e.g., a `draw()` method that behaves differently for `Circle` and `Square` objects).\n",
      "    *   **Abstraction:** Hiding complex implementation details and exposing only essential information.\n",
      "\n",
      "**Dunder Methods (Magic Methods):**\n",
      "\n",
      "*   **What they are:** Special methods in Python that start and end with double underscores (e.g., `__init__`, `__str__`).\n",
      "*   **Purpose:** Define how objects behave with built-in functions and operators.  They enable operator overloading and customization of object behavior.\n",
      "*   **Examples:**\n",
      "    *   `__init__`:  Constructor (called when an object is created).\n",
      "    *   `__str__`:  String representation of an object (used by `str()` and `print()`).\n",
      "    *   `__repr__`:  Unambiguous string representation of an object.\n",
      "    *   `__len__`:  Length of an object (used by `len()`).\n",
      "    *   `__add__`:  Addition operator (`+`).\n",
      "\n",
      "In essence, OOP provides a way to structure your code, and dunder methods allow you to customize how your objects interact with Python's built-in features.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "system_instruction = \"\"\"\n",
    "You are an expert in python programming, you will always provide idiomatic code, i.e.\n",
    "pythonic code. So when you see my code or my question, be very critical, but answer\n",
    "in a SHORT and CONCISE way. Also be constructive to help me improve. \n",
    "\"\"\"\n",
    "\n",
    "prompt = \"\"\"\n",
    "Explain OOP and dunder methods.\n",
    "\"\"\"\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.0-flash\",\n",
    "    contents=prompt,\n",
    "    config=types.GenerateContentConfig(\n",
    "        system_instruction=system_instruction\n",
    "        # thinking_config=types.ThinkingConfig(thinking_budget=0)\n",
    "    ),\n",
    ")\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2ebb6ada",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GenerateContentResponseUsageMetadata(\n",
       "  candidates_token_count=393,\n",
       "  candidates_tokens_details=[\n",
       "    ModalityTokenCount(\n",
       "      modality=<MediaModality.TEXT: 'TEXT'>,\n",
       "      token_count=393\n",
       "    ),\n",
       "  ],\n",
       "  prompt_token_count=70,\n",
       "  prompt_tokens_details=[\n",
       "    ModalityTokenCount(\n",
       "      modality=<MediaModality.TEXT: 'TEXT'>,\n",
       "      token_count=70\n",
       "    ),\n",
       "  ],\n",
       "  total_token_count=463\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata = response.usage_metadata\n",
    "metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "abeebc03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metadata.candidates_token_count = 393\n",
      "metadata.prompt_token_count = 70\n",
      "metadata.total_token_count = 463\n"
     ]
    }
   ],
   "source": [
    "print(f\"{metadata.candidates_token_count = }\") # output\n",
    "print(f\"{metadata.prompt_token_count = }\") # prompt + system instruction\n",
    "print(f\"{metadata.total_token_count = }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8af89fe7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 43)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(prompt.split()), len(system_instruction.split())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58fbb23a",
   "metadata": {},
   "source": [
    "## Temperature\n",
    "\n",
    "- controls randomness of output -> 'creative'\n",
    "\n",
    "its a hyperparameter that can be adjusted to influence the diversity and creativity of the generated text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0315cc72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The gray rabbit twitched its nose, sensing the distant rumble of a lawnmower and immediately darted into the overgrown rose bushes. Safe within the thorny embrace, it nibbled on a fallen petal, the sweet scent masking the fear that still lingered in its twitching whiskers.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "story = \"write a 2 sentence story about a gray rabbit\"\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.0-flash\",\n",
    "    contents=story,\n",
    "    config=types.GenerateContentConfig(\n",
    "        temperature=0\n",
    "        # system_instruction=system_instruction\n",
    "        # thinking_config=types.ThinkingConfig(thinking_budget=0)\n",
    "    ),\n",
    ")\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e09b2557",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The gray rabbit twitched its nose, sensing the distant rumble of a lawnmower and immediately darted into the overgrown rose bushes, its fluffy tail disappearing in a flash of white. Safe within the thorny embrace, it nibbled on a fallen petal, the sweet scent masking the mechanical threat.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.0-flash\",\n",
    "    contents=story,\n",
    "    config=types.GenerateContentConfig(\n",
    "        temperature=0\n",
    "        # system_instruction=system_instruction\n",
    "        # thinking_config=types.ThinkingConfig(thinking_budget=0)\n",
    "    ),\n",
    ")\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "eaba3e86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Barnaby, a gray rabbit with ears perpetually dusted in soil, unearthed a carrot so long it dragged behind him like a regal train. He puffed with pride, already envisioning the delicious crunch, before realizing he'd pulled up Mrs. Higgins' prize-winning parsnip instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.0-flash\",\n",
    "    contents=story,\n",
    "    config=types.GenerateContentConfig(\n",
    "        temperature=2.0\n",
    "        # system_instruction=system_instruction\n",
    "        # thinking_config=types.ThinkingConfig(thinking_budget=0)\n",
    "    ),\n",
    ")\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "587e2f02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The gray rabbit twitched his nose, sensing the storm rolling in. He hopped into his burrow just as the first raindrops began to fall, grateful for his cozy, dry shelter.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.0-flash\",\n",
    "    contents=story,\n",
    "    config=types.GenerateContentConfig(\n",
    "        temperature=2.0\n",
    "        # system_instruction=system_instruction\n",
    "        # thinking_config=types.ThinkingConfig(thinking_budget=0)\n",
    "    ),\n",
    ")\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab0b208c",
   "metadata": {},
   "source": [
    "## Multimodal input\n",
    "\n",
    "input text and image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "af0ac9e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a close-up photo of a fluffy, gray rabbit wearing a miniature white-and-black Swedish student graduation cap (\"studentm√∂ssa\") with a blue and yellow ribbon draped over its back. The rabbit is resting on a gray carpet.\n"
     ]
    }
   ],
   "source": [
    "text_input = \"Describe this image shortly\"\n",
    "image_input = {\"mime_type\": \"image/png\", \"data\": open(\"bella.png\", 'rb').read()}\n",
    "\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.5-pro\",\n",
    "    contents=dict(\n",
    "        parts=[dict(text = text_input), dict(inline_data = image_input)]\n",
    "    )\n",
    ")\n",
    "\n",
    "print(response.text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-engineering-robin-sundman-nilsson-de24 (3.14.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
